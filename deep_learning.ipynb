{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 李宏毅-深度学习\n",
    "https://www.bilibili.com/video/BV1b4411S7Ky/?spm_id_from=333.788.videocard.4\n",
    "\n",
    "定义一个神经网络的三个步骤:\n",
    "1. build nn\n",
    "2. 确定cost function\n",
    "3. 确定优化函数\n",
    "![](deep_learning/img/dl01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review basic structure\n",
    "https://www.bilibili.com/video/BV1b4411S7Ky/?spm_id_from=333.788.videocard.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fully connected layer\n",
    "Dense层在数学上看，就是 输入n为的向量Vn乘以一个矩阵，transform为m维的向量Vm，再经过激活函数做非线性变换\n",
    "\n",
    "$$V_m=\\sigma(V_n*W_{n*m})$$\n",
    "### 符号表示\n",
    "![](deep_learning/img/dl02.png)\n",
    "![](deep_learning/img/dl03.png)\n",
    "![](deep_learning/img/dl04.png)\n",
    "![](deep_learning/img/dl05.png)\n",
    "![](deep_learning/img/dl06.png)\n",
    "![](deep_learning/img/dl07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Structure\n",
    "![](deep_learning/img/dr01.png)\n",
    "### Deep RNN\n",
    "![](deep_learning/img/dr02.png)\n",
    "\n",
    "### bidirectional RNN \n",
    "![](deep_learning/img/dr04.png)\n",
    "\n",
    "### pyramidal RNN\n",
    "DeepRNN, 合并时间步长\n",
    "![](deep_learning/img/dr05.png)\n",
    "### Naive RNN\n",
    "![](deep_learning/img/dn01.png)\n",
    "### LSTM\n",
    "![](deep_learning/img/dn03.png)\n",
    "![](deep_learning/img/dn04.png)\n",
    "![](deep_learning/img/dn06.png)\n",
    "$\\odot$表示element-wise的相乘 \n",
    "\n",
    "向量Zi: input gate,决定输入能否流进去\n",
    "\n",
    "向量Zf: forget gate, 决ct-1能否传入下一个时间点\n",
    "\n",
    "向量Zo: output gate,\n",
    "![](deep_learning/img/dn07.png)\n",
    "![](deep_learning/img/dn08.png)\n",
    "\n",
    "\n",
    "![](deep_learning/img/lstmresult.png)\n",
    "### GRU\n",
    "![](deep_learning/img/dn09.png)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN | Pooling\n",
    "https://www.bilibili.com/video/BV1b4411S7Ky/?p=2  开始时间 5min\n",
    "\n",
    "Simplify nn(based on prior knowledge of the task\n",
    "\n",
    "![](deep_learning/img/cnn01.png)\n",
    "![](deep_learning/img/cnn02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conception\n",
    "* receptive field  \n",
    "    感受野，来自生物学概念\n",
    "* filter(kernel)\n",
    "    * filter(kernel) size  \n",
    "        该filter覆盖的感受野的大小\n",
    "    * Stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积对应什么样的数学操作\n",
    "CNN的卷积运算为何使用互相关而不是卷积 https://blog.csdn.net/appleyuchi/article/details/86574350\n",
    "\n",
    "通俗理解【卷】积+互相关与卷积 https://blog.csdn.net/Sunny_HQ/article/details/80875664\n",
    "\n",
    "\n",
    "一个二维矩阵经过卷积核处理后是什么结果？当kernel划过对应的感受野时，对应的数学运算叫互相关(即把kernel对应位置和其覆盖的位置对应相乘，然后结果求和)\n",
    "![](deep_learning/img/cnnm01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN的卷积运算并非数学定义的卷积\n",
    "\n",
    "也就是说，CNN中的运算是不需要翻转卷积核的。\n",
    "\n",
    "也就是说，CNN在处理图像时的卷积核是不需要翻转180°的\n",
    "\n",
    "我们来用代码看下为什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------卷积结果---------------------\n",
      "[[0.00e+00 3.00e+00 3.00e-01]\n",
      " [6.00e+00 3.06e+01 3.00e+02]\n",
      " [6.00e+01 6.00e+02 0.00e+00]]\n",
      "---------互相关结果---------------------\n",
      "[[  0.  300.   30. ]\n",
      " [600.   60.3   3. ]\n",
      " [  0.6   6.    0. ]]\n"
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "import numpy as np\n",
    "A=np.array([[0,0,0,0],\\\n",
    "                [0,0,30,0],\\\n",
    "                [0,60,0,0],\\\n",
    "                [0,0,0,0]])\n",
    "\n",
    "B=np.array([[0.1,0.01],\\\n",
    "                [1,10]])\n",
    "import scipy.signal\n",
    "print(\"---------卷积结果---------------------\")\n",
    "print( scipy.signal.convolve(A,B,mode='valid'))\n",
    "print(\"---------互相关结果---------------------\")\n",
    "print( scipy.signal.correlate(A,B,mode='valid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为卷积层后面连接的是池化层，\n",
    "也就是说把卷积结果得到的矩阵中，\n",
    "选取矩阵中数值最大的元素作为保留，矩阵中其余元素一律删除。\n",
    "\n",
    "所以我们可以看到：\n",
    "上述代码的\n",
    "卷积结果中的最大值\n",
    "与\n",
    "互相关结果矩阵中的最大值\n",
    "都是600\n",
    "因此后面maxpooling层进行池化后得到的值也都是600.\n",
    "\n",
    "如果后面接全连接层，那么\n",
    "上面两个矩阵全部flatten以后输入dense层，几乎完全一致，也不影响建模\n",
    "\n",
    "结论：\n",
    "CNN中使用卷积或互相关，对于\n",
    "的贡献是一致的，都是获取像素最大的那个值，\n",
    "因此可以使用卷积，也可以使用互相关，\n",
    "但是为了代码的高效，直接使用“互相关”即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example-1D signal+Multiple Channel\n",
    "![](deep_learning/img/cnn03.png)\n",
    "![](deep_learning/img/cnn04.png)\n",
    "![](deep_learning/img/cnn05.png)\n",
    "![](deep_learning/img/cnn06.png)\n",
    "![](deep_learning/img/cnn07.png)\n",
    "![](deep_learning/img/cnnp01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Graph\n",
    "https://www.bilibili.com/video/BV1b4411S7Ky/?p=3\n",
    "![](deep_learning/img/cg01.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward Network 前馈网络的计算图画法\n",
    "$$y=\\sigma(W^L...\\sigma(W^2\\sigma(W^1x+b^1)+b^2)...+b^L)$$\n",
    "![](deep_learning/img/cgl01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function of Feedforward Network\n",
    "![](deep_learning/img/cgl02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient of Cost Function\n",
    "![](deep_learning/img/cg02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在反向求微分时，遇到的问题是: C是标量，而y, z2, a1, z1等都是向量，标量对向量，向量对向量如何求偏微分呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jacobian Matrix\n",
    "向量对向量求偏微分的结果，是一个矩阵，行数是分子向量的维度，列数是分母向量的维度\n",
    "![](deep_learning/img/cg03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实例求解\n",
    "#### $\\frac{\\partial C}{\\partial{y}}$\n",
    "以loss function为cross entropy loss为例说明\n",
    "$$CrossEntropyLoss: l(\\vec y, \\vec{\\hat y})=-\\sum_{i=1}^n\\hat{y_i}ln(y_i)=-ln(y_r)$$，其中$\\hat{y_i}$的第r维为1，其余为0\n",
    "其中$\\vec y$为预测值，$\\vec{\\hat{y}}$为真实值, \n",
    "\n",
    "$$\\frac{\\partial C}{\\partial{y}}=[0 ... \\frac{-1}{y_r} ...]$$\n",
    "![](deep_learning/img/cgr01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\frac{\\partial y}{\\partial z^2}$\n",
    "以\\sigma为sigmoid函数为例\n",
    "$$\\vec y=[y_1\\ y_2\\ ...]=[\\sigma(z_1^2)\\ (\\sigma z_2^2)\\ ....]$$\n",
    "![](deep_learning/img/cgr02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\frac{\\partial z^2}{\\partial a^1}$\n",
    "$$\\frac{\\partial z^2}{\\partial a^1}=W^2$$\n",
    "![](deep_learning/img/cgr03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\frac{\\partial z^2}{\\partial W^2}$\n",
    "把矩阵拉平为向量\n",
    "![](deep_learning/img/cgr04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\frac{C}{\\partial W^1}$\n",
    "![](deep_learning/img/cgr05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Graph for Recurrent Network\n",
    "输入为时间步长为1步\n",
    "![](deep_learning/img/cgr11.png)\n",
    "输入为时间步长为3步\n",
    "![](deep_learning/img/cgr12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![](deep_learning/img/cgr14.png)\n",
    "![](deep_learning/img/cgr15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention and Transformer\n",
    "## 翻译中的attention\n",
    "https://www.bilibili.com/video/BV1b4411S7Ky?p=8  25min attention  by 李宏毅\n",
    "\n",
    "https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/ 过程可视化\n",
    "\n",
    "传统的seq2seq模型，先由encoder把一个句子编码为一个向量，然后把这个向量作为decoder的输入，每次时间步都输入，直到decoder产生结束标志为止。\n",
    "\n",
    "传统的seq2seq模型的问题是 整个句子被编码为一个向量，decoder看到的是相同的。\n",
    "![](deep_learning/img/att00.png)\n",
    "而以机器翻译为例，输入句子的不同部分对输出的影响是不同的。所以引出了attention\n",
    "![](deep_learning/img/att01.png)\n",
    "z0是一个初始的向量，其参数可以学出来\n",
    "![](deep_learning/img/att02.png)\n",
    "z1是把c0丢进decoder中rnn的隐层输出，\n",
    "![](deep_learning/img/att03.png)\n",
    "把z1再和h1...等算一次得到c1\n",
    "![](deep_learning/img/att04.png)\n",
    "![](deep_learning/img/att06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "https://www.bilibili.com/video/BV13t411j7PM/?spm_id_from=333.788.videocard.0\n",
    "\n",
    "https://jalammar.github.io/illustrated-transformer/\n",
    "\n",
    "Transformer是一个典型的encoder-decoder结构\n",
    "![](deep_learning/img/trans01.png)\n",
    "![](deep_learning/img/trans02.png)\n",
    "![](deep_learning/img/trans03.png)\n",
    "![](deep_learning/img/trans04.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "#### Scaled Dot-Product Attention\n",
    "$$Attention(Q,K,V)=softmax(\\frac{QK^T}{\\sqrt d_k})V$$\n",
    "Q,K,V是3个矩阵\n",
    "\n",
    "    Q=np.array([q1,q2...])\n",
    "    K=np.array([k1,k2...])\n",
    "    V=np.array([v1,v2...])\n",
    "#### self-attention\n",
    "Q,K,V来自同一个序列\n",
    "![](deep_learning/img/trans05.png)\n",
    "输入是一个序列thinking machines，输出是一个序列z1,z2。可以看出，attention和rnn的作用是一致的\n",
    "\n",
    "attention和rnn的不同点是，attention的输出如z1考虑了整个序列后得到的，rnn的输出只考虑了相应的时间步长之前的序列\n",
    "\n",
    "attention的计算可以并行化，而rnn由于必须先得到之前序列的向量，才能计算当前序列的向量，因此不能并行\n",
    "![](deep_learning/img/trans06.png)\n",
    "#### Matrix Calculation of Self-Attention\n",
    "![](deep_learning/img/atte01.png)\n",
    "![](deep_learning/img/atte02.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multi-head attention\n",
    "重复把上面的过程做了n次，可以改进性能的原因是 可以关注多个不同的位置。Transformer使用八个关注头\n",
    "![](deep_learning/img/trans07.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Decoder Side\n",
    "现在，我们已经涵盖了编码器方面的大多数概念，我们基本上知道了解码器的组件也如何工作。 但是，让我们看一下它们如何协同工作。\n",
    "\n",
    "编码器首先处理输入序列。 然后，顶部编码器的输出转换为注意向量K和V的集合。每个解码器将在其“encoder-decoder attention”层中使用它们，这有助于解码器将注意力集中在输入序列中的适当位置："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Final Linear and Softmax Layer\n",
    "解码器堆栈输出浮点向量。 我们如何把它变成一个词？ 这就是最后的线性层，然后是Softmax层的工作。\n",
    "\n",
    "线性层是一个简单的完全连接的神经网络，它将解码器堆栈产生的向量投影到一个更大的向量中，称为logits vector。\n",
    "\n",
    "假设我们的模型知道从其训练数据集中学习的10,000个唯一的英语单词（我们模型的“输出词汇”）。 这将使logits向量的宽度变为10,000个单元-每个单元对应一个唯一单词的分数。 这就是我们解释模型的输出以及线性层的方式。\n",
    "\n",
    "然后，softmax层将那些分数转换为概率（全部为正，全部相加为1.0）。 选择具有最高概率的单元，并生成与该单元相关联的单词作为该时间步的输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert\n",
    "[The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](https://jalammar.github.io/illustrated-bert/)\n",
    "\n",
    "BERT is basically a trained Transformer Encoder stack. \n",
    "\n",
    "![](deep_learning/img/att07.png)\n",
    "\n",
    "这两种BERT模型的尺寸都有大量的编码器层（which the paper calls Transformer Blocks）–基本版本为十二层，大型版本为二十四层。 与初始论文中Transformer的参考实现中的默认配置（6个编码器层，512个隐藏单元， 和8个关注头）相比，这些设备还具有更大的前馈网络（分别为768和1024个隐藏单元）和更多关注头（分别为12和16）。\n",
    "## Model Inputs\n",
    "为第一个输入令牌提供特殊的[CLS]令牌，其原因将在以后变得显而易见。 CLS在这里代表分类。\n",
    "\n",
    "就像transformer的编码器一样，BERT接受一系列单词作为输入，这些单词一直在堆栈中向上流动。 每一层都进行自我关注，并将其结果通过前馈网络传递，然后将其传递给下一个编码器。\n",
    "![](deep_learning/img/att08.png)\n",
    "\n",
    "在架构方面，到目前为止，这与Transformer相同（除了大小，这只是我们可以设置的配置）。 首先，在输出端我们开始看到事情如何分歧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Outputs\n",
    "每个位置输出一个大小为hidden_size（在BERT Base中为768）的向量。 对于上面我们看过的句子分类示例，我们仅关注第一个位置（我们将特殊的[CLS]令牌的输出。\n",
    "\n",
    "该向量现在可以用作我们选择的分类器的输入。 本文仅通过使用单层神经网络作为分类器就取得了很好的效果。\n",
    "![](deep_learning/img/att09.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 花书\n",
    "http://www.deeplearningbook.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "270.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
